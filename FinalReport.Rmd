---
title: "Survival Analysis on Linking Drug Dependent Adults to Primary Care"
output: pdf_document
---

# Introduction

Note: might want to think more about the TITLE, after finishing the doc. Is it informative, specific and precise?

BP1: What is survival analysis? What does it do?

Survival analysis estimates the expected duration of time until an event occurs. An event may be death, motorcycle breakdown, etc. In this survival analysis project, we use the dataset HELPfull, which contains data from the paper "Linking alcohol- and drug-dependent adults to primary medical care: a randomized controlled trial of a multi-disciplinary health intervention in a detoxification unit."

BP2: What is the dataset and key variables? What is the purpose of the research?

The HELP study measures the utilization of primary medical care of adult patients from a detox program. Some patients receive a combination of treatment that is intended to increase their primary care usage. Some of the key variables include group (treatment variable), dayslink (response variable), linkstatus (censoring variable), commonly used demographic variables (gender, age, education level), and  medical variables (drug usage, mental health index, etc.).

BP3: How are the variables coded?  What do you do with factor variables?  Lots of missing, what should be done about that?  Which variables are most interesting?

Some variables are binary, some variables are coded as factors, and some variables are numeric. (what did we do with factor transformations?) (what did we do about missing data?) (most interesting variables?) FINISH LATER

BP4: why do we want to research anything about the HELPfull data? What is its relevance?

The research is important, because it may provide insights that improve the treatment of detox programs. If more patients from detox programs can ask for medical help more often and sooner with nudging like the treatment, then it is possible to address this societal issue more effectively. In addition, significant and positive results may give researchers more confidence to research applicable solutions to other social issues, such as homeslessness, bankruptcy, etc.

BP5:  What are some of the initial goals we have in mind? What do we plan to do (exploration of variables, focus on a specific target, building a model, new thing)? Is the final paragraph a brief description of the hypothesis/goals and findings of the paper?

The primary goal is to build a Cox PH model that best predicts survival outcome (using primary healthcare). Our initial hypothesis is the treatment is effective at getting patients connected with primary healthcare. We want to first visualize and understand the variables in the dataset, then look for some interesting and potentially important variables to include in the final model. We will then refine the final model and apply additional techniques to examine the model, such as cox.zph function and bootstrapping techniques.


# Methods
Note: The methods should be a source of detail about the approaches of the authors. Procedures that have been repeated by the authors should only be listed once. Variations to the procedure should be briefly summarized.

Our goal is to create a model that can predict survival outcome. Since the dataset and code are included and shared, we believe the work can be replicated. We will first visualize some data (including mutating some variables), figure out the variables we want to use, and then build the model.


## Exploratory Data Analysis

For our exploratory data analysis, we will observe relationship the explanatory variables have with the response variables, linkstatus. Analyzing the relationship between the explanatory and response variable will help select the variables we want to include in the final model.

First, we will import the packages and dataset.
```{r, warning=FALSE, message=FALSE}
library(mosaic)
library(readr)
library(tidyverse)
library(broom)
library(survival)
library(survminer)
library(praise)

# import the dataset HELPFUL. Encode NAs as "*"
df <- read_csv("HELPdata.csv", na="*")
```

Now that the dataset is imported, we can select our variables of interest. Note that the original dataset has some variables encoded as characters types. We converted these variables to a factor type, so categorical variables are easily distinguishable in our plots.

```{r, message=FALSE, warning=FALSE}
df <- df %>%
  mutate(yrs_education = as.numeric(a9),
         gender=a1,
         alcq_30 = as.numeric(alcq_30),
         marriage = as.factor(a10),
         employment = as.factor(a13),
         income = as.factor(case_when(a18 == 1 ~ "<5000",
                                      a18 == 2 ~ "5000-10000",
                                      a18 == 3 ~ "11000-19000",
                                      a18 == 4 ~ "20000-29000",
                                      a18 == 5 ~ "30000-39000",
                                      a18 == 6 ~ "40000-49000",
                                      a18 == 7 ~ "50000+")),
         income_1yr = as.factor(case_when(a18_rec1 == 0 ~ "$19,000",
                                      a18_rec1 == 1 ~ "$20,000-$49,000",
                                      a18_rec1 == 2 ~ "$50,000")),
         any_util = as.factor(case_when(any_util == 0 ~ "No",
                                        any_util == 1 ~ "Yes")),
         attempted_suicide = as.factor(case_when(g1c == 0 ~ "No",
                                                 g1c == 1 ~ "Yes")),
         employment = as.factor(
           case_when(a13 == 1 ~ "Full time",
                     a13 == 2 ~ "Part time",
                     a13 == 3 ~ "Student",
                     a13 == 4 ~ "Unemployed",
                     a13 == 5 ~ "Ctrl_envir")),
         homeless = as.factor(case_when(homeless == 0 ~ "No",
                                        homeless == 1 ~ "Yes")),
         hs_grad = as.factor(case_when(hs_grad == 0 ~ "No",
                                       hs_grad == 1 ~ "Yes")),
         group = as.factor(case_when(group == 0 ~ "Control",
                                     group == 1 ~ "Clinic")),
         # linkstatus = as.factor(case_when(linkstatus == 0 ~ "Did not link to primary care", linkstatus == 1 ~ "Linked to Primary Care")),
         alcohol = as.factor(case_when(alcohol == 0 ~ "Not First Drug",
                                       alcohol == 1 ~ "First Drug Alcohol")),
         money_spent_on_alcohol = as.numeric(h16a),
         mh_index = as.numeric(mh),
         num_med_problems = as.numeric(d3),
         num_hospitilizations = as.numeric(d1),
         bothered_by_med = as.factor(case_when(d4 == 0 ~ "Not at all",
                                               d4 == 1 ~ "Slightly",
                                               d4 == 2 ~ "Moderately",
                                               d4 == 3 ~ "Considerably",
                                               d4 == 4 ~ "Extremely")),
         bothered = as.factor(case_when(d4_rec == 0 ~ "No",
                                        d4_rec == 1 ~ "Yes"))) %>%
  select(group, dayslink, linkstatus,
         yrs_education, gender, age,
         alcohol, alcq_30, marriage,
         employment, income, income_1yr,
         any_util, attempted_suicide, homeless,
         hs_grad, money_spent_on_alcohol,
         mh_index, num_med_problems,
         num_hospitilizations,bothered_by_med, bothered)
```
Note: based on our final results, we may end up removing some lines of unused variables (for the final report).

We begin by exploring some general variables in clinical research, such as age, gender, education level, and trial-specific variables, such as alcohol usage and medical conditions.

We want to create different data visualizations, in order to understand the relationship between variables and get more clues on the model building.

Since we are working with multiple categorical binary variables, we used the facet functionality to look at multiple survival probability plots simultaneously.

The plot below shows four survival probability plots separated by whether the individual's first drug was alcohol and gender. Gender is encoded as 1=Male and 2=Female. We mutated ALCOHOL to a string, alcohol "as first drug" or "not as first drug". The p-values represent significance for the log-rank test. A p-value less than 0.05 suggests evidence that the survival curves are not equal in favor of the alternative hypothesis, $H_0: \text{ the survival curves are equal}$.

```{r, message=FALSE, warning=FALSE}
care_fit <- survfit(Surv(dayslink, linkstatus) ~ group, data=df)
ggsurvplot_facet(care_fit, df, facet.by = c("gender", "alcohol"), pval = TRUE) +
  ggtitle("Survival Curves Based on Alcohol as 1st/2nd Drug and Gender")
```
Looking at the plot, we see a p-value greater than 0.05 for observations whose first drug was not alcohol and gender is female. This means we fail to reject the null hypothesis that the survival curves are equal.

We want to see if there are some things to keep in mind, when it comes to the gender variable.

```{r}
df %>%
  select(gender, alcohol) %>%
  mutate(gender_str = as.factor(case_when(gender == 1 ~ "Male",
                                          gender == 2 ~ "Female"))) %>%
  mutate(alcohol_str = as.factor(case_when(alcohol == 0 ~ "Not First Drug",
                                           alcohol == 1 ~ "First Drug Alcohol"))) %>%
  ggplot() + geom_bar(aes(x=gender_str, fill=alcohol)) +
  xlab("Gender") +
  ylab("Number of Observations") +
  ggtitle("People who Used Alcohol as First/Second Drug by Gender")
```
Note that the number of female participants are much less than the number of male participants. We will take this into consideration, when building the final model.

Going in another direction, here we observe the relationships mental health index and attempted suicide have on the linkstatus.
```{r}
df %>%
  mutate(linkstatus = as.factor(case_when(linkstatus == 0 ~ "Did not link to primary care",
                                          linkstatus == 1 ~ "Linked to Primary Care"))) %>%
  select(group, linkstatus, dayslink, income, mh_index, attempted_suicide) %>%
  ggplot() +
  geom_point(aes(x=dayslink, y=mh_index, color=linkstatus)) +
  facet_grid(vars(attempted_suicide), vars(group)) +
  ylab("Mental Health Index") +
  xlab("Time") +
  ggtitle("Mental Health Index Grouped by Attemped Suicide and Study Response")
```
We see a distinct separation in response variable divided by the clinic and control group. In general, more individuals in the clinic group linked to primary care sooner than the control group. On the y-axis, a lower mental health index seems to be associated with more suicide attempts.

Next, we look at income and first drug alcohol and relation to the linkstatus.
```{r}
df %>%
  select(income, employment, alcohol, group, linkstatus) %>%
  mutate(linkstatus = as.factor(case_when(linkstatus == 0 ~ "Did not link to primary care",
                                          linkstatus == 1 ~ "Linked to Primary Care")),) %>%
  ggplot() + geom_bar(aes(x=income, fill=employment)) +
  facet_grid(vars(alcohol), vars(linkstatus)) +
  coord_flip() +
  ggtitle("Primary Care Status Based on Income and Alcohol 1st/2nd Drug") +
  xlab("Income") +
  ylab("Number of Observations")
```
Observe that the number of people in the $\$40,000 - \$49,000$ income bracket is much smaller than the other brackets. This could pose statistical confusion in our model building progress, as the small number in that group could skew results.

Based on the exploratory data analysis, non-explanatory variables can influence the primary care linkstatus. For our model building, we will separate the medical and socioeconomic variables. We hypothesize that patients with more medical related problems would be inclined to connect to primary care. (anything else?)

## Stepwise Regression

We proceed with stepwise regression. For each potential variable, we build a coxph model with the variable and one without. Then, we take the loglik deviation from the models and run a drop-in-deviance test. The drop-in-deviance test will help us determine if this additional variable, $x_i$, should be included in the model. The $G$ statistic equals $2*(logLik_{bigger model} - logLik_{smaller model})$. Calculating degrees of freedom is taking the difference in the number of parameters of the full model minus the restricted model. Finding the p-value is the "percentage of the $X^2$ distribution that exceeds G". We calculate the p-value by finding the converse of $phcisq(...)$, or $1 - pchisq(...)$. The null and alternative hypothesis for this test is $H_0: \beta_i = 0$ and $H_a: \beta_i \neq 0$.

Since there were many variables to consider, we wrote a function that takes in the full and small model and returns a p-value from the drop-in-deviance test.

(very specific, very good, wonder if we need to add or trim any info)

```{r}
# input: (small model's glance output, big model's glance output, degrees of freedom)
drop_in_dev <- function(smallmodel, bigmodel, df){
  small_loglik <- smallmodel$logLik
  big_loglik <- bigmodel$logLik
  G = 2*(big_loglik - small_loglik)
  return(1-pchisq(G, df))
}
```

### Medical Explanatory Variables

We first consider the variable "attempted suicide".
```{r}
full_model <- coxph(Surv(dayslink, linkstatus) ~ group + attempted_suicide, data=df) %>% glance()
restricted_model <- coxph(Surv(dayslink, linkstatus) ~ group, data=df) %>% glance()
drop_in_dev(restricted_model, full_model, 1)
```
The change in deviance is 0.3692, $(H_0: \gamma=0)$, so with one degree of freedom the p-value is 0.543385, which is greater than 0.05. We fail to reject the null hypothesis and do not need this variable in the model.

Next, we consider the mental health index.
```{r}
full_model <- coxph(Surv(dayslink, linkstatus) ~ group + mh_index, data=df) %>% glance()
restricted_model <- coxph(Surv(dayslink, linkstatus) ~ group, data=df) %>% glance()
drop_in_dev(restricted_model, full_model, 1)
```
The change in deviance is 0.1908, $(H_0: \gamma=0)$, so with one degree of freedom the p-value is 0.6622516, which is greater than 0.05. We fail to reject the null hypothesis and do not need this variable in the model.

Now, we consider gender.
```{r}
full_model <- coxph(Surv(dayslink, linkstatus) ~ group + gender, data=df) %>% glance()
restricted_model <- coxph(Surv(dayslink, linkstatus) ~ group, data=df) %>% glance()
drop_in_dev(restricted_model, full_model, 1)
```
The change in deviance is 3.1354, $(H_0: \gamma=0)$, so with one degree of freedom the p-value is 0.07660959, which is greater than 0.05. Note that the p-value is close to 0.05, which suggests that there could be little evidence. We fail to reject the null hypothesis and do not need this variable in the model.

We consider the variable "alcohol", or whether alcohol is the user's first or second drug.
```{r}
full_model <- coxph(Surv(dayslink, linkstatus) ~ group + alcohol, data=df) %>% glance()
restricted_model <- coxph(Surv(dayslink, linkstatus) ~ group, data=df) %>% glance()
drop_in_dev(restricted_model, full_model, 1)
```
The change in deviance is [1] 8.2646. $(H_0: \gamma=0)$, so with one degree of freedom the p-value is 0.004042557, which is less than 0.05. We reject the null hypothesis that $\gamma=0$ in favor of $H_a: \gamma \ne 0$ and should include first drink alcohol in the model.

Now we consider the number of medical problems, in addition to "alcohol".
```{r}
full_model <- coxph(Surv(dayslink, linkstatus) ~ group + num_med_problems + alcohol, data=df) %>% glance()
restricted_model <- coxph(Surv(dayslink, linkstatus) ~ group + alcohol, data=df) %>% glance()
drop_in_dev(restricted_model, full_model, 1)
```
We see that the p-value for the additive model for treatment groups and the number of medical problems is insignificant (0.07209521). Note that the p-value is relatively close to 0.05, but do not include number of medical problems because we aim to produce the simplest model.

Since gender has a p-value close to 0.05, we are interested in seeing if the additive model with alcohol will pass the drop-in-deviance test.
```{r}
full_model <- coxph(Surv(dayslink, linkstatus) ~ group + gender + alcohol, data=df) %>% glance()
restricted_model <- coxph(Surv(dayslink, linkstatus) ~ group + alcohol, data=df) %>% glance()
drop_in_dev(restricted_model, full_model, 1)
```
The p-value is 0.1809207. This does not suggest evidence to reject the null hypothesis that $\beta_i = 0.$ (additional analysis sentence)

### Socioeconomic Explanatory Variables

The p-values from the drop-in-deviance tests do not suggest adding all of the medical based variables, except for first drink alcohol. We will look to socioeconomic variables like age, income, employment, homeless, and high school graduation.

First, we consider age.
```{r}
full_model <- coxph(Surv(dayslink, linkstatus) ~ group + alcohol + age, data=df) %>% glance()
restricted_model <- coxph(Surv(dayslink, linkstatus) ~ group + alcohol, data=df) %>% glance()
drop_in_dev(restricted_model, full_model, 1)
```
0.04584322 < 0.05. We reject the null hypothesis and include age.

Next, we consider employment.
```{r, message=FALSE, warning=FALSE}
full_model <- coxph(Surv(dayslink, linkstatus) ~ group + alcohol + age + employment, data=df) %>% glance()
restricted_model <- coxph(Surv(dayslink, linkstatus) ~ group + alcohol + age, data=df) %>% glance()
drop_in_dev(restricted_model, full_model, 1)
```
A p-value of 0.06941881 means we fail to reject the null hypothesis that $\beta_i = 0$. We do not include employment.

Consider the binary variable, homeless.
```{r, message=FALSE, warning=FALSE}
full_model <- coxph(Surv(dayslink, linkstatus) ~ group + alcohol + age + homeless, data=df) %>% glance()
restricted_model <- coxph(Surv(dayslink, linkstatus) ~ group + alcohol + age, data=df) %>% glance()
drop_in_dev(restricted_model, full_model, 1)
```
A p-value of 0.7095458 means we fail to reject the null hypothesis that $\beta_i = 0$. We do not include homeless.

Now we consider income.
```{r, message=FALSE, warning=FALSE}
full_model <- coxph(Surv(dayslink, linkstatus) ~ group + alcohol + age + income, data=df) %>% glance()
restricted_model <- coxph(Surv(dayslink, linkstatus) ~ group + alcohol + age, data=df) %>% glance()
drop_in_dev(restricted_model, full_model, 1)
```
A p-value of 1.733154e-08 means we reject the null hypothesis that $\beta_i = 0$. We include income in our model.

Now, the years of education.
```{r}
full_model <- coxph(Surv(dayslink, linkstatus) ~ group + alcohol + age + yrs_education, data=df) %>% glance()
restricted_model <- coxph(Surv(dayslink, linkstatus) ~ group + alcohol + age, data=df) %>% glance()
drop_in_dev(restricted_model, full_model, 1)
```
A p-value of 1.126592e-05 means we reject the null hypothesis that $\beta_i = 0$. We include the "years of education" variable in our model.

We want to see if the status of high school graduation should be included in the model.
```{r}
full_model <- coxph(Surv(dayslink, linkstatus) ~ group + alcohol + age + yrs_education + hs_grad, data=df) %>% glance()
restricted_model <- coxph(Surv(dayslink, linkstatus) ~ group + alcohol + age + yrs_education, data=df) %>% glance()
drop_in_dev(restricted_model, full_model, 1)
```
A p-value of 0.08662291 means we fail to reject the null hypothesis that $\beta_i = 0$. We do not include high school graduation in our model.


The tentative final model is $exp\{ \beta_1group + \beta_2age + \beta_3alcohol + \beta_4income + \beta_5YearsEducation\}$.
```{r}
coxph(Surv(dayslink, linkstatus) ~ group + age + alcohol + income + yrs_education, data=df)
```
Above are the coefficients for the model. Note that the the p-values of income levels are all greater than 0.05. In fact, the p-value for income40000-49000 is smaller than the other income coefficients by a factor of 100. One reason behind the smaller p-value is that the number of individuals with income between 40000-49000 are less than the other income groups.

Looking the plot, "Primary Care Status Based on Income and Alcohol 1st/2nd Drug", we see a drop in the number of individuals for the 40000-49000 income group. So even though the drop-in-deviance test is significant, the outliers could be dragging the p-value down. Thus, we will not be proceeding with income.

(biggest question: how much of the above should be in Results instead, and which ones should be shortened?) FINISH LATER

# Results

The Cox PH analysis should include: an interpretation of your final survival model including a discussion of the sign of the coefficients (note: feel free to use interactions)

Note: Is the content appropriate for a results section? Simple introduction to the scientific question. Clear description of the results for each experiment. Analysis of those results.

Note: Are the results/data analyzed well? Given the data in each figure, is the interpretation accurate and logical? Is the analysis of the data thorough or are some aspects of the data ignored? Does the author make connections between ideas (graphs, models, etc.) within the text? Are the data interpreted in a larger context?

Note: Figures. Are the figures appropriate for the data being discussed?. Are the figure legends and titles clear and concise?

Our final model is as follows:
```{r}
model1 <- coxph(Surv(dayslink, linkstatus) ~ group + age + alcohol + yrs_education, data=df)
model1
```
More formally,
\[ h_i(t)  = h_0exp\{-1.76952\cdot \text{Group} + 0.02609\cdot\text{Age} -0.42942\cdot\text{Alcohol} - 0.11815\cdot\text{YearsOfEducation}\}. \]

The most drastic change in risk for $\hat{HR}$ comes from a unit increase in group. That is, a change from the treatment group to the control group,  decreases risk by a factor of $exp\{-1.76952\} = 0.1704148$.
The change in risk for a transition from alcohol being a first drug to non-alcoholic first drug decreases by $exp\{-0.42942\} = 0.6508865$.
Last, a unit increase in years in education decreases by $exp\{-0.11815\} = 0.8885628$.


Which variable(s) are in? Which are out?

What do you conclude about linking to primary care? Is there anything worth mentioning about how you got to your final model?

What can you say about causation? What can you say about generalizing to a larger population?


## New Ideas

We choose to learn two new ideas, related to survival analysis. Michael will investigate assumptions about proportional hazard. Oliver will investigate the bootstrapping methods for the survival model.

### Cox.zph

Cox PH models have an underlying assumption that hazards are proportional. The ratio between two results are constant over time, or presents a linear relationship. But hazard ratios are sometimes non-proportional, such as when KM curves cross, or one tapers off and another drops to zero.  In fact, if we do not assume a baseline hazard rate and time invariant (meaning constant) coefficients and variables, the Cox PH model will not be accurate. To test the proportionality assumption of the Cox PH model, we use the cox.zph function.

The cox.zph function tests the proportionality of every (prediction) variable in the model. It does so by creating interactions with time in various time transformation. (https://stats.idre.ucla.edu/r/examples/asa/r-applied-survival-analysis-ch-6/)
If the p-value is less than 0.05 for a coefficient, then it means the coefficient does not contribute linearly to the PH model and violates the proportionality asumption. If the p-values are big, then we do not reject the null hypothesis. This indicates the model hazard is porportional.

We want to make sure that the hazards are proportional to make the Cox PH model work. If they are not, then we want to see if transforming the time variable can bring back proportionality. If such attempt is successful, we can transform the original time variable in the dataset and revise the model, without starting from scratch. (http://st47s.com/Math150/Notes/survival-analysis.html) The code is given below, note that the basic cox.zph model and the completed default cox.zph model produce the same results.

```{r}
cox.zph(model1)
# without tranform, it assumes transform = "km"

# includes every condition in the vignette, the results are still the same by default settings
# cox.zph(fit, transform="km", terms=TRUE, singledf=FALSE, global=TRUE)
cox.zph(coxph(Surv(dayslink, linkstatus) ~ group + age + alcohol + yrs_education, data=df), terms = TRUE, singledf = FALSE, global = TRUE)

# model interacts with log(time)
cox.zph((model1), transform="log")
```

Here we see that for both methods of transformation, only group does not contribute linearly to the proportionality assumption. However, this may not be unacceptable, since group is a binary explanatory variable. We can leave it as as is. The other predictors pass the proportionality test.

We also want to look at the residual plots of the model, since non-proportional hazards indicate variables that do not contribute linearly to the model. These residuals are called the Scoenfeld residuals, each predictor variable has its own plot. The plot function and the ggcoxzph function both plot the same residuals, the only difference is the former plots them separately, the latter plots them together similar to a facet function. The plots will also produce three regression lines.

Schoenfeld residuals essentially revert the regression process. Let's call the explanatory variable X and the response variable Y. Previously we want to predict Y given X and the residual is the difference between the predicted Y and the observed Y. With Shoenfeld residuals, we want to predict X given Y and find the difference between the predicted X and the observed X. The following article is a comprehensive source on Schoenfeld residuals with Python. (https://towardsdatascience.com/schoenfeld-residuals-the-idea-that-turned-regression-modeling-on-its-head-b1f1fd293f87)

```{r}
plot(cox.zph(model1))
# the plot shows the Schoenfeld residuals in 4 plots

ggcoxzph(cox.zph(coxph(Surv(dayslink, linkstatus) ~ group + age + alcohol + yrs_education, data=df)))
# the plot shows the Schoenfeld residuals in 1 big plot
```

The mean of Schoenfeld residuals is zero, if the regression coefficients of the Cox PH model are not dependent on time. In fact, if the Cox PH model is indeed proportional, then the Schoenfeld residuals should be randomly distributed given a large dataset. We observe a more randomly distributed Schoenfeld residual plots, except the group variable. Therefore we are okay with using this Cox PH model, since group is our explanatory variable and the other predictor variables pass the proportionality test. (https://towardsdatascience.com/schoenfeld-residuals-the-idea-that-turned-regression-modeling-on-its-head-b1f1fd293f87)

```{r}
ggcoxzph(cox.zph(coxph(Surv(dayslink, linkstatus) ~ group + age + alcohol + yrs_education, data=df)))

ggcoxdiagnostics(coxph(Surv(dayslink, linkstatus) ~ group + age + alcohol + yrs_education, data=df))
```

### Bootstrapping the Survival Model

For your analysis, you should give details of what is going on, how it is relevant, what are the technical conditions, what are the conclusions,
etc.

### Discussion
Does the author clearly state whether the results answer the question? (i.e. support or disprove the hypothesis?)
Were specific data cited from the results to support each interpretation? Does the author clearly articulate the basis for
supporting or rejecting the hypothesis ?
Does the author adequately relate the results of the current work to previous research?
Does the author appropriately discuss to whom the results can be generalized?

### References (for new ideas)
Are the references appropriate and of an adequate quantity?
Are the references cited properly (both within the text and at the end of the paper)?

### Writing Quality (final check in the evening, read it out loud)
Is the paper well organized? (Paragraphs are organized in a logical manner)
Is each paragraph well written? (Clear topic sentence, single major point)
Is the paper generally well written? (Good use of language, sentence structure)
